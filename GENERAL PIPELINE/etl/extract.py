# -*- coding: utf-8 -*-
"""extract.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BW8AZLtIQYNnxa_SxRhgD5OU-XPldQ0u
"""

import os
import json
import hashlib
import requests
import pandas as pd
from datetime import datetime
from .utils import ensure_dir, load_config

# ====================================================
# CONFIG (Defaults, but can be overridden by user input)
# ====================================================
LOCAL_FILE = None
METADATA_FILE = "/GENERAL PIPELINE/metadata/metadata.json"
RESOURCE_URL = None

# ====================================================
# LOGGING
# ====================================================
def log(msg):
    print(f"[LOG {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}")


# ====================================================
# HASH FUNCTION
# ====================================================
def file_hash(file_path):
    sha256 = hashlib.sha256()
    with open(file_path, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            sha256.update(chunk)
    return sha256.hexdigest()


# ====================================================
# USER INPUT DECISION FUNCTION (NEW)
# ====================================================
def choose_input(source=None):
    
    global RESOURCE_URL
    global LOCAL_FILE

    # Direct source passed programmatically
    if source is not None:
        # ... (rest of direct source logic)
        return

    print("\nChoose dataset input option:")
    print("1) Use an existing LOCAL FILE")
    print("2) DOWNLOAD dataset using a URL link")

    choice = input("Select 1 or 2: ")

    if choice == "1":
        local_path = input("Enter local file path: ").strip()
        LOCAL_FILE = local_path 

    elif choice == "2":
        url = input("Enter dataset URL: ").strip()
        RESOURCE_URL = url 

    else:
        log("Invalid choice. Using default configuration...")



# ====================================================
# DOWNLOAD DATASET
# ====================================================
# Remove the default value from the function signature.
# We will use the module-level RESOURCE_URL inside the function.
def download_dataset(url=None, output=None, save_metadata=True): 
    global LOCAL_FILE 

    config = load_config()
    default_raw = config["paths"]["raw"]  # always a FILE, never a folder

    # 1. Argument Handling
    if url is None:
        url = RESOURCE_URL
    
    if output is None:
        output = LOCAL_FILE 

    # 2. Critical Path/URL Checks
    if url is None:
        raise ValueError("Cannot download: RESOURCE_URL is not set.")
    
    # 3. Resolve output (always RAW file)
    if output is None:
        log(f"No output provided → Using RAW path: {default_raw}")
        output = default_raw

    LOCAL_FILE = output

    log(f"Downloading dataset from:\n{url}")

    # Now, 'url' will be the value set by choose_input (the URL you typed)
    response = requests.get(url, allow_redirects=True) 

    if response.status_code != 200:
        raise Exception(f"ERROR: dataset could not be downloaded. Código: {response.status_code}")

    # =============================================
    # SAVE METADATA
    # =============================================
    # Ensure Directory Exists (Fixes FileNotFoundError WinError 3)
    output_dir = os.path.dirname(output)
    if output_dir:
        ensure_dir(output_dir) # Use your utility to create the 'staging/' folder

    # Write the File to Disk (Previously Missing)
    with open(output, "wb") as f:
        # response.content holds the file data (as bytes)
        f.write(response.content) 
        
    log(f"Dataset successfully saved as: {output}")

    # Save Metadata (Completing the function)
    if save_metadata:
        # Ensure imports for os, json, datetime, file_hash are correct at module top
        metadata = {
            "source": "User Provided URL",
            "url": url,
            "download_date": datetime.now().isoformat(),
            "file": output,
            "encoding": "latin-1",
            "file_size_bytes": os.path.getsize(output), # Now safe because the file exists
            "sha256_hash": file_hash(output)
        }

        # Assuming METADATA_FILE is defined globally
        ensure_dir(os.path.dirname(METADATA_FILE)) 
        with open(METADATA_FILE, "w", encoding="utf-8") as f:
            json.dump(metadata, f, indent=4, ensure_ascii=False)

        log("Metadata saved in metadata.json")
        
    return output # Return the path to the loaded file


# ====================================================
# LOAD DATA
# Priority:
#   1) Use local file (if exists)
#   2) Download automatically
# ====================================================
def load_dataset():
    # 1) Check existing local file ONLY if LOCAL_FILE has been set
    if LOCAL_FILE is not None:
        if os.path.exists(LOCAL_FILE): # Now this is safe
            log(f"local file found: {LOCAL_FILE}")
            return LOCAL_FILE
        else:
            log(f"Specified local file not found: {LOCAL_FILE}")
            # If a local file path was specified by the user but doesn't exist, 
            # we should usually stop or ask the user again, 
            # but for now, we'll proceed to the download logic if RESOURCE_URL is available.
    
    # Check if a download URL is available before attempting download
    if RESOURCE_URL is not None:
        # 2) Download
        log("No local file found (or none specified). Downloading automatically...")
        download_dataset()
        return LOCAL_FILE # LOCAL_FILE is updated inside download_dataset
    else:
        # If no local file specified AND no RESOURCE_URL available (e.g., invalid choice '3')
        raise FileNotFoundError("Cannot load dataset: No local file specified and no download URL available.")


# ====================================================
# MAIN EXTRACT FUNCTION (USED IN PIPELINE)
# ====================================================
def extract_dataset(source=None):
    """
    Main extract function used by pipeline.py.

    Optional parameter:
        source = user-defined local file OR URL
    """
    # Let user or pipeline define input
    choose_input(source)

    file_path = load_dataset()

    log("Loading dataset (from extract_dataset)...")
    df = pd.read_csv(file_path, encoding="latin-1")
    log("Dataset loaded successfully (extract_dataset).")

    metadata = {
        "source": RESOURCE_URL if RESOURCE_URL else "Local File",
        "url": RESOURCE_URL,
        "file": file_path,
        "encoding": "latin-1",
        "download_date": datetime.now().isoformat(),
        "sha256_hash": file_hash(file_path)
    }

    return df, metadata
