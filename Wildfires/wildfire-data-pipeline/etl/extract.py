# -*- coding: utf-8 -*-
"""extract.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BW8AZLtIQYNnxa_SxRhgD5OU-XPldQ0u
"""

import os
import json
import hashlib
import requests
import pandas as pd
from datetime import datetime
from etl.utils import ensure_dir

# ====================================================
# CONFIG
# ====================================================
LOCAL_FILE = '/wildfire-data-pipeline/data/raw/incendios_forestales.csv'
METADATA_FILE = "/wildfire-data-pipeline/metadata/metadata.json"
#METADATA_FILE = "wildfire-data-pipeline\metadata.json"
RESOURCE_URL = "https://www.datos.gob.mx/dataset/3a1d4a71-4dad-4ae9-9eec-44de7fa8ebf3/resource/ddf38874-6243-4437-8f76-19f797cafa5c/download/estadisticasincendiosforestales2015-2024.csv"


# ====================================================
# LOGGING
# ====================================================
def log(msg):
    print(f"[LOG {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}")


# ====================================================
# HASH FUNCTION
# ====================================================
def file_hash(file_path):
    sha256 = hashlib.sha256()
    with open(file_path, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            sha256.update(chunk)
    return sha256.hexdigest()


# ====================================================
# DOWNLOAD DATASET
# ====================================================
def download_dataset(url=RESOURCE_URL, output=LOCAL_FILE, save_metadata=True):
    log(f"Downloading dataset from:\n{url}")

    response = requests.get(url, allow_redirects=True)

    if response.status_code != 200:
        raise Exception(f"ERROR: dataset could not be downloaded. Código: {response.status_code}")
    
    ensure_dir(os.path.dirname(output))


    with open(output, "wb") as f:
        f.write(response.content)

    log(f"Dataset downloaded as: {output}")

    # =============================================
    # SAVE METADATA
    # =============================================
    if save_metadata:
        metadata = {
            "source": "Comisión Nacional Forestal (CONAFOR)",
            "url": url,
            "download_date": datetime.now().isoformat(),
            "file": output,
            "encoding": "latin-1",
            "file_size_bytes": os.path.getsize(output),
            "sha256_hash": file_hash(output)
        }

        with open(METADATA_FILE, "w", encoding="utf-8") as f:
            json.dump(metadata, f, indent=4, ensure_ascii=False)

        log("Metadata saved in metadata.json")



# ====================================================
# LOAD DATA
# Priority:
#
#   1) Use local file
#   2) Download automatically
# ====================================================
def load_dataset():
    # 1) Check existing local file
    if os.path.exists(LOCAL_FILE):
        log(f"local file found: {LOCAL_FILE}")
        return LOCAL_FILE

    # 2) Download
    log("No local file found. Downloading automatically...")
    download_dataset()
    return LOCAL_FILE

# =========================================
# NEW FUNCTION REQUIRED BY THE PIPELINE
# =========================================
def extract_dataset():
    """
    Main extract function used by pipeline.py.
    """
    file_path = load_dataset()
    log("Loading dataset (from extract_dataset)...")
    df = pd.read_csv(file_path, encoding="latin-1")
    log("Dataset loaded successfully (extract_dataset).")
    
    metadata = {
        "source": "CONAFOR",
        "url": RESOURCE_URL,
        "file": file_path,
        "encoding": "latin-1",
        "download_date": datetime.now().isoformat(),
        "sha256_hash": file_hash(file_path)
    }

    return df, metadata